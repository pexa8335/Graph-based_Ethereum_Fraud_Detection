import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
import joblib
import numpy as np
import pandas as pd
import json  # ThÃªm import json Ä‘á»ƒ load metadata
from ml_transformers import IntelligentImputer, ControlCharacterCleaner, ColumnDropper

class ImprovedFraudGNN(torch.nn.Module):
    def __init__(self, num_features):
        super().__init__()
        self.conv1 = GCNConv(num_features, 64)
        self.conv2 = GCNConv(64, 32)
        self.conv3 = GCNConv(32, 16)  # ThÃªm conv3 Ä‘á»ƒ khá»›p state_dict (layer thá»«a tá»« training)
        self.classifier = torch.nn.Linear(32, 2)
        self.dropout = torch.nn.Dropout(0.5)

    def forward(self, x, edge_index):
        x = F.relu(self.conv1(x, edge_index))
        x = self.dropout(x)
        x = F.relu(self.conv2(x, edge_index))
        return self.classifier(x)  # KhÃ´ng dÃ¹ng conv3, giá»‘ng nhÆ° code training

def load_artifacts():
    pipeline = joblib.load('../Model/preprocessing_pipeline.pkl')
    with open('../Model/metadata.json', 'r') as f:
        metadata = json.load(f)
    num_features = metadata['features']['final_features_count']
    feat_names = metadata['features']['final_features_list']
    model = ImprovedFraudGNN(num_features)
    model.load_state_dict(torch.load('../Model/fraud_gnn_weights.pth', map_location='cpu'))
    model.eval()
    return model, pipeline, feat_names

def predict_address(model, pipeline, features_dict):
    # Load metadata Ä‘á»ƒ láº¥y thá»© tá»± chÃ­nh xÃ¡c
    with open('../Model/metadata.json', 'r') as f:
        metadata = json.load(f)
    expected_columns = metadata['features']['final_features_list']  # Giá»¯ key nhÆ° attachment cá»§a báº¡n

    df = pd.DataFrame([features_dict])

    # Debug: In Ä‘á»ƒ kiá»ƒm tra trÆ°á»›c reorder
    print("ğŸ” Features columns before reorder:", df.columns.tolist())

    # Reorder vÃ  fill default náº¿u thiáº¿u cá»™t
    missing_cols = set(expected_columns) - set(df.columns)
    for col in missing_cols:
        df[col] = 0.0  # Fill 0 cho cá»™t thiáº¿u
    df = df[expected_columns]  # Reorder theo thá»© tá»± chÃ­nh xÃ¡c

    # Debug: In sau reorder
    print("âœ… Features columns after reorder:", df.columns.tolist())

    x_proc = pipeline.transform(df)
    x_tensor = torch.tensor(x_proc, dtype=torch.float32)
    edge_index = torch.tensor([], dtype=torch.long).reshape(2, 0)
    with torch.no_grad():
        logits = model(x_tensor, edge_index)
        probs = torch.softmax(logits, dim=1)[0]
        pred = int(torch.argmax(probs))
        percent = float(probs[pred]) * 100
    return "fraud" if pred == 1 else "non-fraud", percent/100, percent

def explain_address(model, pipeline, features_dict, feat_names, topk=None):  # ThÃªm topk optional Ä‘á»ƒ khá»›p vá»›i app.py, nhÆ°ng bá» qua nÃ³
    # TÆ°Æ¡ng tá»±, thÃªm reorder cho hÃ m nÃ y Ä‘á»ƒ trÃ¡nh lá»—i náº¿u gá»i
    with open('../Model/metadata.json', 'r') as f:
        metadata = json.load(f)
    expected_columns = metadata['features']['final_features_list']  # Giá»¯ key nhÆ° attachment

    df = pd.DataFrame([features_dict])

    # Debug: In Ä‘á»ƒ kiá»ƒm tra trÆ°á»›c reorder
    print("ğŸ” Explain features columns before reorder:", df.columns.tolist())

    # Reorder vÃ  fill default
    missing_cols = set(expected_columns) - set(df.columns)
    for col in missing_cols:
        df[col] = 0.0
    df = df[expected_columns]

    # Debug: In sau reorder
    print("âœ… Explain features columns after reorder:", df.columns.tolist())

    x_proc = pipeline.transform(df)
    x_tensor = torch.tensor(x_proc, dtype=torch.float32)
    importance = model.conv1.lin.weight.abs().sum(dim=0).detach().numpy()
    feat_names_aligned = feat_names if len(feat_names) == len(importance) else [f"f{i}" for i in range(len(importance))]

    # Sáº¯p xáº¿p táº¥t cáº£ features theo importance giáº£m dáº§n (bá» qua topk)
    idx = importance.argsort()[::-1]  # Tá»« cao Ä‘áº¿n tháº¥p
    all_features = np.array(feat_names_aligned)[idx]
    all_importance = importance[idx].round(3)

    # Convert numpy.float32 sang float Ä‘á»ƒ serialize JSON
    feature_importance = {feat: float(value) for feat, value in zip(all_features, all_importance)}

    return {
        "explanation": "Giáº£i thÃ­ch importance cá»§a táº¥t cáº£ cÃ¡c Ä‘áº·c trÆ°ng (sáº¯p xáº¿p tá»« áº£nh hÆ°á»Ÿng cao nháº¥t Ä‘áº¿n tháº¥p nháº¥t)",
        "feature_importance": feature_importance
    }
